# ðŸ“Š Data Analysis and Visualisation â€“ Recruitment Fairness Project  

## ðŸ“Œ Overview  
This project focuses on building a predictive and interpretable machine learning pipeline for recruitment data. Using a dataset of job applicants, the aim was to explore patterns, build classification models, and evaluate fairness to ensure ethical AI-driven hiring decisions.  

---

## ðŸŽ¯ Objectives  
- Explore applicant data through feature engineering and pattern discovery  
- Build classification models to predict hiring outcomes  
- Apply **explainability methods** (SHAP, LIME) for transparency  
- Test models for **fairness** (group & individual metrics)  

---

## ðŸ›  Methods & Techniques  

### ðŸ”¹ Data Preparation  
- Discretization and feature engineering (e.g., referee alignment & diversity)  

### ðŸ”¹ Unsupervised Learning  
- K-Medoids clustering to uncover subgroup hiring patterns  

### ðŸ”¹ Association Rule Mining  
- Apriori algorithm for identifying hiring-related rules  

### ðŸ”¹ Supervised Learning  
- Decision Trees  
- Random Forest  
- Bagging  
- AdaBoost  
- **XGBoost** (best performing, ~98% accuracy)  

### ðŸ”¹ Explainability  
- **SHAP** â†’ global feature importance  
- **LIME** â†’ local instance-level explanations  

### ðŸ”¹ Fairness Testing  
- Group fairness (gender, age, university background)  
- Individual fairness (similarity-based consistency)  

---

## ðŸ“ˆ Key Findings  
- **Academic performance** (A-levels) strongly influenced hiring outcomes  
- **Referees** (quality, diversity, alignment) had measurable effects, raising fairness concerns  
- **XGBoost** outperformed other classifiers with strong predictive accuracy and generalisation  
- **Fairness analysis** showed high individual fairness but potential bias towards elite universities  

---

## ðŸ§° Tools & Libraries  
- Python â†’ pandas, numpy, scikit-learn, matplotlib, seaborn  
- mlxtend â†’ association rule mining  
- pyclustering â†’ K-Medoids  
- SHAP, LIME â†’ explainability  
- XGBoost  

---

## ðŸ’¡ Reflections  
This project demonstrates how advanced machine learning techniques can be integrated with ethical considerations such as fairness and interpretability. By combining predictive performance with fairness analysis, it offers a blueprint for responsible AI in recruitment systems.  
